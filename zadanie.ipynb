{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jatoja123/image-classification/blob/main/zadanie.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYLEvf8HEzNt"
      },
      "source": [
        "# Przygotowania\n",
        "Zadanie zacząłem od krótkiego researchu. Wybrałem bibliotekę pytorch jako bazę projektu, ponieważ jest przystępna do użytku i adekwatna do tego zadania."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qQKxsHaDz8m"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchvision.transforms import v2 as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(DEVICE)\n",
        "is_cuda = DEVICE == \"cuda:0\"\n",
        "\n",
        "# do testowania\n",
        "train_data_percent = 0.85  # tyle % danych bedzie uzytych do treningu, pozostale do finalnego testowania\n",
        "epochs = 40 # ilosc powtorzen treningu na danych treningowych\n",
        "square_images = False # czy zmieniac obrazki na kwadraty\n",
        "calculate_mean_std = True # czy wyliczac wartosci mean i std dla danych\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pu7nLW2mFb3-"
      },
      "source": [
        "# Dane\n",
        "Pobrałem dane do zadania i dodatkowo zdefiniowałem klasę, która później umożliwi wczytanie tych danych."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqdU0rLiE5R9"
      },
      "outputs": [],
      "source": [
        "# pobieranie danych do zadania\n",
        "import kagglehub\n",
        "data_path = kagglehub.dataset_download(\"gergvincze/simple-hand-drawn-and-digitized-images\")\n",
        "print(data_path)\n",
        "\n",
        "# klasy wzięte z zadania\n",
        "classes = ('smiley', 'envelope', 'peace_symbol', 'bicycle', 'balloon', 'anchor', 'thumb', 'speech_bubble', 'spiral', 'paper_boat')\n",
        "\n",
        "# własna klasa agregacji danychx\n",
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "from PIL import Image\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, data_path, classes, transform=None, indices=None):\n",
        "        self.data_path = data_path\n",
        "        self.classes = classes\n",
        "        self.transform = transform\n",
        "        self.image_files = []\n",
        "        all_image_files = []\n",
        "        for class_name in self.classes:\n",
        "            class_path = os.path.join(self.data_path, class_name)\n",
        "            for filename in os.listdir(class_path):\n",
        "                all_image_files.append((os.path.join(class_path, filename), self.classes.index(class_name)))\n",
        "\n",
        "        if indices is None:\n",
        "            self.image_files = all_image_files\n",
        "        else:\n",
        "            #Filtruj indeksy\n",
        "            self.image_files = [all_image_files[i] for i in indices]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path, label = self.image_files[idx]\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# dane surowe\n",
        "if square_images: image_resize = (128, 128)\n",
        "else: image_resize = 128\n",
        "\n",
        "raw_transforms = transforms.Compose([\n",
        "    transforms.ToImage(),\n",
        "    transforms.Resize(image_resize),\n",
        "    transforms.ToDtype(torch.float32, scale=True),\n",
        "])\n",
        "rawset = CustomImageDataset(data_path, classes, raw_transforms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Vq5xnE4hRr6"
      },
      "source": [
        "## Analiza surowych danych\n",
        "Jest dziesięć klas danych (przeczytałem je z nazw folderów).\n",
        "Sprawdziłem jaki jest rozkład danych na klasy..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3acc9d6e"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "all_labels = [label for _, label in rawset.image_files]\n",
        "label_counts = Counter(all_labels)\n",
        "class_names = [classes[i] for i in label_counts.keys()]\n",
        "counts = [label_counts[i] for i in label_counts.keys()]\n",
        "\n",
        "plt.figure(figsize=(8, 3))\n",
        "plt.bar(class_names, counts)\n",
        "plt.xlabel(\"Klasa\")\n",
        "plt.ylabel(\"Liczba obrazków\")\n",
        "plt.title(\"Rozkład klas w danych\")\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIuD4lz3-6Dg"
      },
      "source": [
        " ...na szczęście w miarę równy. Gdyby było inaczej np. danych z jakiejś klasy byłoby za mało to model słabo by się nauczył tej klasy, a w przypadku za dużej ilości - nauczył tylko tej, a innych słabiej. Wtedy trzeba by było kombinować."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOtJN_5zhzF8"
      },
      "source": [
        "## Normalizacja danych\n",
        "Zdecydowałem się na normalizację danych, ponieważ bardzo korzystnie wpływa to na szybkość uczenia się modelu, tym bardziej, że w zestawie danych znajdują się zdjęcia, które mogły być wykonane przy różnym oświetleniu i warunkach.\n",
        "\n",
        "Normalizacja zdefiniowana jest przez wartości mean i std. Mogłem użyć domyślnych (0.5), ale znalazłem sposób żeby wygenerować je dla moich danych, co powinno zwiększyć skuteczność modelu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwyGzLuSh3te"
      },
      "outputs": [],
      "source": [
        "def compute_mean_std(dataset):\n",
        "    loader = DataLoader(dataset, batch_size=64, shuffle=False, num_workers=2)\n",
        "    mean = 0.0\n",
        "    std = 0.0\n",
        "    total_images = 0\n",
        "\n",
        "    for images, _ in loader:\n",
        "        batch_samples = images.size(0)\n",
        "        images = images.view(batch_samples, images.size(1), -1)\n",
        "        mean += images.mean(2).sum(0)\n",
        "        std += images.std(2).sum(0)\n",
        "        total_images += batch_samples\n",
        "\n",
        "    mean /= total_images\n",
        "    std /= total_images\n",
        "    return np.array(mean), np.array(std)\n",
        "\n",
        "mean, std = [0.5,0.5,0.5], [0.5,0.5,0.5]\n",
        "\n",
        "if calculate_mean_std:\n",
        "  mean, std = compute_mean_std(rawset)\n",
        "\n",
        "print(\"Mean:\", mean)\n",
        "print(\"Std:\", std)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rx_EpDPD_t_d"
      },
      "source": [
        "Potem sprawdziłem też wyniki dla wartości 0.5, ale na razie bez spoilerów."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VuQpLbwEzop"
      },
      "source": [
        "## Powiększenie danych treningowych (Data augmentation)\n",
        "Pytorch daje dostęp do prostego mechanizmu modyfikacji danych podczas treningu (transformacji). Służy to lepszemu wytrenowaniu modelu i pomaga uniknąć przetrenowania.\n",
        "\n",
        "Jako że danych surowych jest bardzo mało, transformacje będą kluczowe, żeby zasymulować większą ich ilość.\n",
        "Transformacje których użyłem to: odbicie horyzontalne, zmiany w kolorze/kontraście/saturacji, obrót i zmiana perspektywy.\n",
        "\n",
        "Oprócz tego lekko zmniejszyłem rozmiar obrazku, żeby przyspieszyć trening."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJeN-X6ZEz9F"
      },
      "outputs": [],
      "source": [
        "# Transformacje treningowe\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.ToImage(),\n",
        "    transforms.Resize(image_resize), # zmniejszenie rozmiaru\n",
        "    transforms.RandomHorizontalFlip(), # losowe horyzontalne odbicie\n",
        "    transforms.RandomRotation(10), # losowy obrót\n",
        "    transforms.RandomPerspective(0.1), # zmiana perspektywy\n",
        "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue = 0.3), # losowe zmiany koloru\n",
        "    transforms.ToDtype(torch.float32, scale=True),\n",
        "    transforms.Normalize(mean, std),\n",
        "])\n",
        "\n",
        "# Transformacje testowe - losowe zmiany nie są potrzebne, bo model i tak nie widział tych danych podczas treningu\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.ToImage(),\n",
        "    transforms.Resize(image_resize),\n",
        "    transforms.ToDtype(torch.float32, scale=True),\n",
        "    transforms.Normalize(mean, std),\n",
        "])\n",
        "\n",
        "fullset = CustomImageDataset(data_path, classes, data_transforms)\n",
        "\n",
        "# Dzielimy dane na dwa zbiory: treningowy i testowy\n",
        "train_size = int(train_data_percent * len(rawset))\n",
        "test_size = len(rawset) - train_size\n",
        "train_indices, test_indicies = random_split(list(range(len(rawset))), [train_data_percent, 1-train_data_percent])\n",
        "\n",
        "trainset = CustomImageDataset(data_path, classes, data_transforms, train_indices)\n",
        "testset = CustomImageDataset(data_path, classes, test_transforms, test_indicies)\n",
        "\n",
        "print(f'Ilość danych treningowych {len(trainset)}')\n",
        "print(f'Ilość danych testowych {len(testset)}')\n",
        "\n",
        "batch_size = 16\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wyświetliłem przykładowe obrazki i efekty transformacji:"
      ],
      "metadata": {
        "id": "ylqcUi6FynF2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HO2s7X3WHWrM"
      },
      "outputs": [],
      "source": [
        "# funkcja do odwracania normalizacji\n",
        "def unnormalize(img_tensor):\n",
        "    global mean\n",
        "    global std\n",
        "    img = img_tensor.numpy().transpose((1, 2, 0))\n",
        "    img = std * img + mean\n",
        "    img = np.clip(img, 0, 1)\n",
        "    return img\n",
        "\n",
        "def show_images(dataset, title, unnormalize_image = True, num_images=8):\n",
        "    fig, axs = plt.subplots(1, num_images, figsize=(12, 2))\n",
        "    fig.suptitle(title, fontsize=16)\n",
        "\n",
        "    for i in range(num_images):\n",
        "        data = dataset[i]\n",
        "        if isinstance(data, tuple):\n",
        "          img, _ = data\n",
        "        else:\n",
        "          img = data\n",
        "\n",
        "        # zmien img tak aby byl obrazkiem w poprawnym formacie\n",
        "        if unnormalize_image: img = unnormalize(img)\n",
        "        elif isinstance(img, torch.Tensor):\n",
        "             img = img.numpy().transpose((1, 2, 0))\n",
        "\n",
        "        axs[i].imshow(img)\n",
        "        axs[i].axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Zobaczmy przykładowe obrazki\n",
        "show_images(rawset, 'Surowe obrazki', False)\n",
        "show_images(fullset, 'Zmodyfikowane obrazki', True)\n",
        "show_images(trainset, 'Inne zmodyfikowane obrazki', True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuU0HJftDW2h"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jako model wybrałem CNN (Convolutional neural network). Jest to właściwy wybór, ponieważ ten typ sieci wzorowany jest na ludzkim wzroku i potrafi wykrywać wizualne cechy, nie ważne w którym miejscu obrazka się znajdują. Jest też polecany przez dokumentację pytorch :D"
      ],
      "metadata": {
        "id": "3JTmN6Sl-nUs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BaembAk7HlKT"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, size_x, size_y):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "\n",
        "        # Calculate the output size of the convolutional and pooling layers dynamically\n",
        "        def output_size(input_size, kernel_size, stride, padding):\n",
        "            return (input_size - kernel_size + 2 * padding) // stride + 1\n",
        "\n",
        "        conv1_y = output_size(size_y, 5, 1, 0)\n",
        "        conv1_x = output_size(size_x, 5, 1, 0)\n",
        "        pool1_y = output_size(conv1_y, 2, 2, 0)\n",
        "        pool1_x = output_size(conv1_x, 2, 2, 0)\n",
        "        conv2_y = output_size(pool1_y, 5, 1, 0)\n",
        "        conv2_x = output_size(pool1_x, 5, 1, 0)\n",
        "        pool2_y = output_size(conv2_y, 2, 2, 0)\n",
        "        pool2_x = output_size(conv2_x, 2, 2, 0)\n",
        "        flattened_size = 16 * pool2_y * pool2_x\n",
        "\n",
        "\n",
        "        self.fc1 = nn.Linear(flattened_size, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "size_y = rawset[0][0].size()[1]\n",
        "size_x = rawset[0][0].size()[2]\n",
        "\n",
        "print(f'Wymiary obrazków: {size_x}x{size_y}')\n",
        "\n",
        "net = Net(size_x, size_y)\n",
        "if is_cuda: net = net.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4_qWRKAM76X"
      },
      "source": [
        "Początkowo użyłem konstrukcji z dokumentacji pytorch, ale nie działała ze względu na różnicę wymiarów obrazków (moje nie były kwadratowe), dlatego zmodyfikowałem ją, aby działała dla dowolnych wymiarów. Tutaj wpadłem na pomysł przetestowania dokładności dla kwadratowych vs prostokątnych obrazków."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9yZO49lESbX"
      },
      "source": [
        "Żeby zwizualizować model użyłem biblioteki torchsummary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "804cba71"
      },
      "outputs": [],
      "source": [
        "%pip install torchsummary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "871951f0"
      },
      "outputs": [],
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "summary(net, input_size=(3, size_y, size_x))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jak widać rozmiar modelu jest naprawdę mały, dwa miliony parametrów to nic w porównaniu do wielkich, współczesnych modeli."
      ],
      "metadata": {
        "id": "lvT5oNpRBiJ3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eui5MEMEj8qK"
      },
      "source": [
        "Jako funkcję loss'u wybrałem proponowany przez pytorch Cross Entropy Loss, który jest zwyczajowo używany do zadań klasyfikacji, gdzie odpowiedź jest prawdopodobieństwem z zakresu [0, 1]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzQRfg1nHwUs"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWjBJsRnkwKX"
      },
      "source": [
        "Uruchomiłem trening modelu:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mtcM_tQHybi"
      },
      "outputs": [],
      "source": [
        "def test_on_dataset(dataloader):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "      for data in dataloader:\n",
        "          images, labels = data\n",
        "          if is_cuda:\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "          outputs = net(images) # predykcje modelu\n",
        "          _, predicted = torch.max(outputs, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "  return 100 * correct // total\n",
        "\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        if is_cuda:\n",
        "          inputs = inputs.cuda()\n",
        "          labels = labels.cuda()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # optymalizacja\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    print(f'[{epoch + 1}] loss: {running_loss:.3f}')\n",
        "    running_loss = 0.0\n",
        "    train_accuracies.append(test_on_dataset(trainloader))\n",
        "    test_accuracies.append(test_on_dataset(testloader))\n",
        "\n",
        "print('Koniec treningu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Dx9o5FRlO0y"
      },
      "source": [
        "# Wyniki\n",
        "### Wyniki tego treningu\n",
        "Sprawdziłem wyniki zrobionego właśnie modelu na danych testowych, czyli takich których jeszcze nie widział."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDoGIqAHRtsv"
      },
      "outputs": [],
      "source": [
        "test_accuracy = test_on_dataset(testloader)\n",
        "print(f'Dokładność na danych testowych: {test_accuracy} %')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yP6MdfKwMR4"
      },
      "source": [
        "Całkiem znośnie!\n",
        "\n",
        "Byłem też ciekawy na ile dobrze radzi sobie z tym, co już widział."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2H3W6z_yqR_e"
      },
      "outputs": [],
      "source": [
        "train_accuracy = test_on_dataset(trainloader)\n",
        "print(f'Dokładność na danych treningowych: {train_accuracy} %')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkgoApW6lSH-"
      },
      "source": [
        "Możemy wyświetlić kilka obrazków i zobaczyć jak model je klasyfikuje."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIRvhpFBNU36"
      },
      "outputs": [],
      "source": [
        "dataiter = iter(testloader)\n",
        "images, labels = next(dataiter)\n",
        "images_cuda = images\n",
        "if is_cuda:\n",
        "  images_cuda = images_cuda.cuda()\n",
        "  labels = labels.cuda()\n",
        "\n",
        "show_images(images, '', True, num_images=len(images))\n",
        "\n",
        "print('Poprawne klasy:      ', ' '.join(classes[label] for label in labels))\n",
        "\n",
        "outputs = net(images_cuda)\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "print('Wypredykowane klasy: ', ' '.join(classes[predict] for predict in predicted))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Wyniki ogólne modelu\n",
        "Zapisywałem wyniki uruchomień dla różnych ustawień, tak żeby później przeanalizować średnie wyniki.\n",
        "\n",
        "Wybrałem ciekawiące mnie ustawienia - czy obrazek kwadratowy oraz czy wartości mean i std generowane dla moich danych."
      ],
      "metadata": {
        "id": "NA1WFOaJBAlJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5w7NHQ1JvSO"
      },
      "outputs": [],
      "source": [
        "# zapisywanie wyników tego treningu do .csv\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "print(f\"Wyniki na danych testowych: {test_accuracies}\")\n",
        "print(f\"Wyniki na danych treningowych: {train_accuracies}\")\n",
        "\n",
        "file_name = 'wyniki.csv'\n",
        "\n",
        "results = pd.DataFrame({\n",
        "    'epoch': range(1, epochs + 1),\n",
        "    'calculate_mean_std': calculate_mean_std,\n",
        "    'square_images': square_images,\n",
        "    'train_data_percent': train_data_percent,\n",
        "    'test_accuracy': test_accuracies,\n",
        "    'train_accuracy': train_accuracies\n",
        "})\n",
        "\n",
        "if os.path.exists(file_name): # dopisz wyniki do pliku\n",
        "    prev_results = pd.read_csv(file_name)\n",
        "    new_results = pd.concat([prev_results, results], ignore_index=True)\n",
        "else:\n",
        "    new_results = results\n",
        "\n",
        "new_results.to_csv(file_name, index=False)\n",
        "print(f\"Zapisano wyniki do pliku: {file_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tu zapisałem moje wyniki:"
      ],
      "metadata": {
        "id": "mmPdDYC6_U0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -O https://raw.githubusercontent.com/jatoja123/image-classification/main/wyniki_1.csv"
      ],
      "metadata": {
        "id": "T3o01ZzO_FP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wyświetlmy wyniki dla kolejnych epok i przeanalizujmy trendy:"
      ],
      "metadata": {
        "id": "dzflT5U2togI"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkP2jbfnlthr"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Usunięto pobieranie nieistniejącego pliku\n",
        "# from google.colab import files\n",
        "# files.download(\"wyniki_1.csv\")\n",
        "\n",
        "# Zmieniono ścieżkę odczytu na plik wyniki_1.csv\n",
        "results = pd.read_csv('wyniki_1.csv')\n",
        "results_test = results.groupby(['epoch', 'calculate_mean_std', 'square_images'])['test_accuracy'].mean().reset_index()\n",
        "results_train = results.groupby(['epoch', 'calculate_mean_std', 'square_images'])['train_accuracy'].mean().reset_index()\n",
        "\n",
        "def filter_data(grouped_data, calculate_mean_std, square_images):\n",
        "  return grouped_data[(grouped_data['calculate_mean_std'] == calculate_mean_std) & (grouped_data['square_images'] == square_images)]\n",
        "\n",
        "plot_test = {\n",
        "    \"własny mean i std, kwadratowe obrazki\": filter_data(results_test, True, True),\n",
        "    \"własny mean i std, prostokątne obrazki\": filter_data(results_test, True, False),\n",
        "    \"mean=0.5 i std=0.5, kwadratowe obrazki\": filter_data(results_test, False, True),\n",
        "    \"mean=0.5 i std=0.5, prostokątne obrazki\": filter_data(results_test, False, False),\n",
        "}\n",
        "\n",
        "plot_train = {\n",
        "    \"własny mean i std, kwadratowe obrazki\": filter_data(results_train, True, True),\n",
        "    \"własny mean i std, prostokątne obrazki\": filter_data(results_train, True, False),\n",
        "    \"mean=0.5 i std=0.5, kwadratowe obrazki\": filter_data(results_train, False, True),\n",
        "    \"mean=0.5 i std=0.5, prostokątne obrazki\": filter_data(results_train, False, False),\n",
        "}\n",
        "\n",
        "def print_results(plot, y, label_y, title):\n",
        "  fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "  for combination_key, df in plot.items():\n",
        "      ax.plot(df['epoch'], df[y], label=combination_key)\n",
        "\n",
        "  ax.set_xlabel(\"Epoka\")\n",
        "  ax.set_ylabel(label_y)\n",
        "  ax.set_ylim([0, 100])\n",
        "  ax.set_title(title)\n",
        "  ax.legend()\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "print_results(plot_test, 'test_accuracy','Średnia dokładność testowa (%)','Średnia dokładność testowa w zależności od epoki i parametrów')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sprawdźmy też jak model radził sobie z danymi, które już widział:"
      ],
      "metadata": {
        "id": "JbOscaasuXZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print_results(plot_train, 'train_accuracy','Średnia dokładność treningowa (%)','Średnia dokładność treningowa w zależności od epoki i parametrów')"
      ],
      "metadata": {
        "id": "q6ScDQpIrPDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVOdSfQPsKKu"
      },
      "source": [
        "# Wnioski i błędy\n",
        "\n",
        "### Rozdzielenie danych treningowych i testowych\n",
        "Na początku nie rozdzieliłem danych na treningowe i testowe przez co wynik był szokujący - aż 96%! Był to błąd, ponieważ nie sprawdzałem wyników modelu na nowych danych, tylko na tych, które już widział. Po poprawce wynik spadł do \"normalnych\" wartości.\n",
        "\n",
        "### Liczba transformacji przy augmentacji danych\n",
        "Danych było niewiele i ciekawiło mnie, jak ilość transformacji wpływa na wyniki.\n",
        "\n",
        "Testowo zmieniłem liczbę różnych transformacji do dwóch (odbicie i zmiana koloru). Dokładność na danych testowych spadła o 10pp, podczas gdy na danych treningowych model uzyskiwał ponad 90% skuteczności - zdecydowanie się przetrenował.\n",
        "\n",
        "Tak jak oczekiwałem, większa różnorodność danych pozytywnie wpłynęła na wynik dla niewidzianych wcześniej obrazków. Przy późniejszym generowaniu tabelki oszczędziłem sobie pracy i nie sprawdzałem wyników dla mniejszej liczby transformacji.\n",
        "\n",
        "### Wymiary obrazków\n",
        "Widziałem, że typowo obrazki wczytuje się do sieci jako kwadraty, ale uznałem, że spróbuję zostać przy prostokątach, dlatego finalnie przetestowałem obie opcje. Wyniki pokazały, że nie wpływa to znacząco na dokładność modelu.\n",
        "\n",
        "### Własne wartości normalizujące vs generyczne\n",
        "Jak widać na powyższych wykresach, własne wartości normalizujące niesamowicie poprawiały wyniki modelu.\n",
        "\n",
        "Wyciągnąłem stąd wniosek, że dobre przygotowanie danych może drastycznie ułatwić/skrócić trenowanie modelu. Dla generycznych wartości model musiał wykonać ponad 3 razy więcej epok żeby osiągnąć ten sam wynik, co model z wygenerowanymi wartościami.\n",
        "\n",
        "### Ogólne wyniki modelu\n",
        "Model był trenowany od zera, przez co spodziewałem się, że wyniki będą słabe. Okazały się być bardzo dobre, to znaczy - przynajmniej mnie usatysfakcjonowały. Myślałem, że będę musiał użyć gotowej sieci i ją dotrenować, ale obyło się bez tego.\n",
        "\n",
        "Wydaje mi się, że duża dokładność wynika z prostych cech w danych. Obrazki z zadania składają się z jednolitego tła i wyraźnych, czarnych linii. Gdyby tła były bardziej różnorodne niż kartka, model uczyłby się dłużej.\n",
        "\n",
        "## Co dalej?\n",
        "Rozwiązanie na pewno nie jest idealne. Z rzeczy, które mógłbym poprawić to pewnie jakość kodu (to zawsze się da).\n",
        "\n",
        "Kolejnym krokiem w optymalizacji byłoby sprawdzenie innych modeli / konstrukcji sieci lub dotrenowanie jakiejś gotowej sieci CNN.\n",
        "\n",
        "Dodatkowo, nie sprawdziłem parametrów, które mogłby okazać się istotne np. ile % danych jest do treningu, a ile do testu oraz wartości transformów przy augmentacji danych. Nie miałem też czasu sprawdzać wyników dla większej liczby epok."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTpFJIOJOyadFRrhNjO+In",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}